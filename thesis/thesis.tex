\documentclass[12pt,a4paper]{book}
\usepackage[utf8]{inputenc}
\usepackage[inline]{enumitem}
\usepackage{parskip} % disable indentation for new paragraphs, increased margin-bottom instead
\usepackage[american,ngerman]{babel}

\usepackage{kit_style/kitthesiscover}

\usepackage[style=alphabetic]{biblatex}
\addbibresource{bib.bib}

\usepackage[%dvipdfm,
   pdfauthor={Christian Schwarz},
   pdftitle={Stage-aware Scheduling in a Library OS},
   pdfsubject={Bachelor Thesis},
   pdfkeywords={Operating Systems, Library OS, Scheduler, Cache-Affinity}
]{hyperref}

\usepackage{todonotes}
\usepackage{blindtext}

\begin{document}
\frontmatter
\unitlength1cm
\selectlanguage{american}

\title{Stage-aware Scheduling in a Library~OS}
\author{cnad. inform. Christian Schwarz}
\thesistype{Bachelor Thesis}
\primaryreviewer{Prof.\ Dr.\ Frank Bellosa}
\advisor{M.\ Sc.\ Mathias Gottschlag}{}
\thesisbegindate{XX.\ December 2017}
\thesisenddate{XX.\ March 2018}
\maketitle

\input{kit_style/declaration}

\chapter{Abstract}
\chapter{Acknowledgments}

\mainmatter
\cleardoublepage
\phantomsection
\addcontentsline{toc}{chapter}{Contents}
\tableofcontents

\chapter{Introduction}
\blindtext

\blindtext

\blindtext

\blindtext

\blindtext

\blindtext

\chapter{Related Work}
We explain motivation and related work in the field of cache-aware scheduling policies / application architecture.
This will borrow heaviliy from the expose.

\section{Profiling at Google (Kanev et al)}
\section{Memory Hierarchy on Contemporary Server-Class CPUs}
\section{SEDA}
\section{Software Data Spreading}
\section{Protoype in Linux at KIT OS Group}
%TODO this section should coin the term stage-aware scheduling, otherwise, we need to do that before the analysis --- rename section with stage-aware in title
A Linux-based proof of concept implementation at the KIT OS group combines the idea of staged execution, cohort
scheduling and software data spreading into a C API that allows for intuitive conversion of existing code bases to
staged execution:
The developer manually identifies stages and inserts library calls into application code for switching the current stage.
Each CPU core is assigned one or more stages and each time a thread switches to a new stage, it is migrated to a core
assigned to that stage.

It is obvious that a fast thread migration mechanism is required for this technique to succeed
--- otherwise, the performance benefits of always-warm caches per stage are destroyed by the migration time.
%\newcommand{\setaffinity}{\texttt{sched\_setaffinity(2)}}
The Linux built-in facility for this purpose, \texttt{sched\_setaffinity}, is impractical because it uses
expensive inter-processor-interrupts to implement this syscall, resulting in $9\mu s$ -- $14\mu s$ of migration time.~\cite{sodaspr}% TODO check on IPs 
As a consequence, thread migration was implemented in user-space:
for each user-level thread (ULT), there still exists exists a kernel-level thread (KLT),
but KLTs are pinned once to a specific core and stage.
ULTs run on a KLT of the stage they are currently in and migrate to a different KLT when switchting stages.
TODO threading model required
TODO automatic -> mathias' paper, when it's published

When a ULT makes a call to switch stages, its context is saved and enqueued into the next stage's ready queue.
The originating KLT now waits for new ULTs on its own stage's incoming migrations queue.
If it is empty, the KLT makes a blocking syscall \texttt{TODO\_dequeue\_syscall} to a kernel component to wait for incoming migrations.
The kernel component must ensure that there is always one KLT per core either doing work or actively dequeuing ULTs in order to utilize the CPU.
This is implemented by a callback from the Linux scheduler that informs the kernel component of task state changes.
For example, if the currently dequeuing KLT $K_1$ executes a ULT, and that ULT blocks on a mutex, $K_1$ switches to \texttt{TASK\_INTERRUPTIBLE}.
The kernel component must wake up another KLT $K_2$ that is currently waiting for incoming migrations of that stage on that core.
Otherwise, the core does not perform any work (for the application) until $K_1$ aquires the mutex and switches back to \texttt{TASK\_RUNNING}

TODO results with single threaded execution, show that it works, reduced cache misses and performance gains are visisble.

However, multithreaded workloads on an SMP system exhibit visible CPU underutilization.
Imagine a system with $\frac{\#cores}{stage} > 1$ and a ULT $U_1$ in stage $S$ executing on a KLT $K_1$.
As described above, $K_1$ is pinned to core $C_1$.
When $U_1$ performs a blocking syscall, for example waiting to aquire a mutex via \texttt{pthread\_mutex\_lock}, $K_1$ blocks and becomes \texttt{TASK\_INTERRUPTIBLE}.
The Linux scheduler now dispatches another task $T$ on $C_1$ to maximize CPU utilization.
(Note that $T$ is not a $K_i$ of our application. In fact, all $K_i$ are blocked in \texttt{TODO\_dequeue\_syscall}.)
When $K_1$ finally aquires the mutex and is \texttt{TASK\_RUNNING} again, it can still only be dispatched to $C_1$ due to pinning which is necessary for user-level thread migration.
However, $C_1$ will be executing $T$, not $K_1$ which is put into $C_1$'s ready queue instead.
The misery at this point is that there may exist \textbf{another} CPU $C_2$ where a KLT $K_2$ is dequeuing ULTs in the \textbf{same stage} $S$:
if $K_2$ does not have any ULTs to execute, $K_1$ should be migrated to $C_2$ immediately when it is woken up and continue execution there, benefiting from the warm on-core caches.
But the implementation only performs thread migration when a ULT calls the stage switching API.
There is no mechanism in place to save $K_1$'s state and enqueue it to $K_2$'s incoming migration queue on wake-up.
(One might assume it is possible to enqueue $U_1$ to $K_2$ since we saved its register state on kernel entry via \texttt{pthread\_mutex\_lock}:
this is not possible because there might still be kernel code that needs to run after the mutex is aquired, before returning to $U_1$.)

TODO UML sequence diagram visualizing the pathological case described above.

\chapter{Analysis}\label{ch:analysis}
Related work has demonstrated that spreading the working set of an application over multiple cores yields lower on-core cache miss rates.
The proof-of-concept implementation at the KIT OS group furthermore shows that large-scale refactoring of existing code bases is not necessarily required to spread the working set:
given a re-usable runtime library, patches of a few lines are sufficient to define migration points in applications with a suitable threading model.

Nonetheless, we identify several fundamental problems in the approach taken by the proof-of-concept implementation:
the requirement for fast thread migration drove the design toward a user-space solution which decouples the threads known by the application (ULTs) from the threads known by the kernel (KLTs).
However, this change was not paralleled by the introduction of an M:N threading model:
there still exists one task (KLT) per thread created by the application code.
The role of KLTs is schizophrenic: for stage migration, KLTs are viewed as the CPUs they are pinned to, because thread migration happens in user space.
But when a ULT running on a KLT interacts with the Linux kernel, the kernel sees a normal \texttt{task\_struct} and continues to assume the 1:1 threading model.
This is the software-architectural root cause for the pathological behavior on multi-core systems:
the kernel --- apart from the solution's kernel component --- has no concept of stages, but this knowledge is required to wake a thread on the right core in a work-conserving manner.

We conclude that the proof-of-concept does not model the situation correctly: the association of stages and CPU cores is piggybacked onto the KLTs using \texttt{sched\_setaffinity}.
Instead, we argue that stages must be modeled explicitly in the kernel and be separate entities, beneath CPUs and threads:
\begin{itemize}
    \item The associaton of stages and CPU cores must be represented explicity.
    \item Threads must carry the information in which stage they are executing.
    \item The scheduler must honor this information by scheduling threads onto cores that are associated with their respective stage.
\end{itemize}
This reverts the complex situation of ULTs and KLTs to a simple 1:1 threading model and enables kernel-activity of threads to be handled without policy exceptions or special callbacks from the scheduler.

The price for this arguably cleaner design is the implementation complexity that comes with it:
the kernel must have a representation of stages, support management of their lifecycle and implement an adaptive scheduling policy for the association of stages and CPU cores.
Furthermore, a multi-tasking kernel scheduler cannot limit its scheduling goals to the minimiziation of cache misses in a single application: % TODO s/multi-tasking/multi-app or multi-tenant/?
global goals such as fairness stay at least equally important and influence the cache state (warm or cold), which in turn influences the usefulness of a stage-aware scheduler.

We conclude that a clean and performant solution for stage-aware scheduling must solve two fundamental problems:
\begin{enumerate}
    \item For work-conservation, explicit representation of stages and tight integration into mechanisms like wake-ups on mutexes, condition variables and timers is required.
    \item The scheduling policy must take cache-state into consideration and trade-off \textit{warm caches through staging} against other scheduling goals.
\end{enumerate}

\chapter{Design \& Implementation}
In this section, we explain our solution to the problems described in Section~\ref{ch:analysis}.
The following enumeration provides an overview of the subsequent subsections:
\begin{enumerate}
    \item We implement our solution in the OSv library operating system, which provides Linux-ABI compatibility and runs on Linux/KVM hypervisor.~(Section~\ref{ch:di:osv})
    \item We remove the existing load balancing and fairness mechanisms from OSv's scheduling policy, replacing it with simple round-robin.~(Section~\ref{ch:di:rmsched})
    \item We add a user-space API to define stages and switch between them as well as a rudimentary CPU allocation policy for stages.~(Section~\ref{ch:di:api})
    \item We implement a new thread migration mechanism that does not use inter-processor interrupts (IPIs) and use it for thread migration on stage switch.~(Section~\ref{ch:di:mig})
    \item We extend the handling of wake-up events for threads that execute in a given stage to migrate to idle CPUs allocated to that stage, making our solution work-conserving on multi-processor systems.~(Section~\ref{ch:di:workcons})
    \item We replace the rudimentary CPU allocation policy with a solution that aims to equalize the number of threads per stage to avoid bottleneck-stages.~(Section~\ref{ch:di:pol})
\end{enumerate}
Each subsection starts with the reasoning behind our design followed by our implementation strategy in OSv as well as the refactorings it required.
We refer to the relevant commits in the Git repository of our modified version of OSv as appropriate.

\section{The OSv Library Operating System}\label{ch:di:osv}
% what is osv, how does it work:
%       libc + linux ABI => unmodified, existign software runs (mention ports), etc
%       compact scheduler implementation => see below
% why OSv for this thesis:
%    small kernel / scheudler => implementation complexity
%    virtual machines         => Linux scheduler for fairness goals, our OSv scheduler can focus on optimal stage-aware scheduling
%
% Design Deficiencies:
%           While offloading almost all other design goals to Linux scheduler makes implementation considerably easier,
%           it is by far not optimal: like all nested dynamic systems, the Linux scheduler and our scheduler can inadvertently work against each other
%           => for simplicitly, we limit our design to a solution where cores are dedicated to the OSv VM

\begin{itemize}
    \item Concept of a library OS: vm = app, no user-kernel-boundary => performance promise
    \item Linux ABI-compat
    \item Moderately sized C++ codebase, compact scheduler implementation
\end{itemize}
Idea: OSv allows for easier replacement of the entire scheduling policy and and thread migration mechanisms.
By the nature of a library OS, the changes are kept application-local, leaving fairness considerations up to the hypervisor scheduler (Linux / KVM in our case).

\subsection{The OSv Scheduler}
This section highlights implementation details of the upstream OSv scheduler that are required to understand the framework in which our implementation was done.
For details, we refer to the TODO paper.
\begin{itemize}
    \item runqueues + idle thread
    \item thread pinning => percpu threads
    \item thread migration mechanism
    \item thread states => state diagram
\end{itemize}

\section{Removal of OSv Scheduling Policy}\label{ch:di:rmsched}
% remove load balancing + fairness (cpu time, priority queue / sorted list? )
% stub out pthreads_sched_setaffinity_np + remove dead thread migration code (why did we do that?)
% implement simple CPU-local round-robin 
% describe outcome:
%   cpu-local runqueues, round robin, non-preemption (OKish because threads always finish, while not really fair...)
%   existing thread migration mechanism still required by percpu threads, but only on startup
%   idle threads are always runnable, dequeue incoming migrations per CPU
%   
\blindtext
\section{User-Space API}\label{ch:di:api}
% Define stages as objects in the kernel
% User-space can enqueue itself to a stage, will be migrated to one of the cores it is assigned to
% Stack structure for implementation comfort, describe idea behind stack structure & guards -> spans, like in web browser
\blindtext
\section{Fast Thread Migration}\label{ch:di:mig}
% Motivation: Stage switch requires migration to other core
% Existing migration mechanism is based on IPIs, is too slow => results, maybe also compare to Linux => adjust hopper
% Must be fast, because of opportunity cost calculation:
%   -> for single client:       cold cache and no migration vs warm cache but migration times
%   -> for T > #cpus clients: ???
% Design:
%       stage migration and hence migration to other CPU core is synchronous to program flow
%       MPSC queue per CPU, for incoming stage migrations
%       on stage switch, evaluate CPU allocation policy, pick target CPU, enqueue into stagesched_incoming
%       target CPU dequeues from stagesched_incoming in idle thread -> mention potential optimization: mwait
%       Measurement results: why not here??? specifically if we discuss mwait?
% Implementation:
%       a stage switch means scheduling out on the source CPU, being migrated to the target CPU and resuming execution there
%       per-cpu MPSC queue that contains pointers to TCBs of threads in stage migration
%       cpu idle thread dequeues from mpsc
%       additional thread states for thread in stage migration
%       critical race condition:  only after scheduling out on the source CPU must execution continue on the target CPU,
%           but thread puts itself into the MPSC queue while it is still executing
%           => augment the thread-switching routine (which is the last code the migrating thread execute on the source CPU) to atomically
%              switch the state of the thread from stagemig_run to stagemig_sto
%           => target CPU only dequeues those threads that are in stagemig_sto to its runqueue, others are still executing code on the source CPU
% => State diagram with changes made in this step
\blindtext
\section{Work Conservation}\label{ch:di:workcons}
% Motivation: with thread migration mechanism in place, we are faster than the Linux solution but not still work conserving
%             when a thread is woken up, it will be enqueued inot the runqueue of the CPU where it went to sleep
%             if that CPU is already executing a thread but another one of the same stage is idle, we do not use the available resources efficiently
%             the woken thread should be migrated to the idle CPU and immediately resume execution there
%             important: this is not stage switching, but also needs to evaluate the CPU allocation policy (forward ref!)
% Design:
%             on wakeup, evaluate the CPU allocation policy and migrate the woken thread to that CPU using the normal thread migration mechanism
% Implementation:
%             wakup is asynchronous, e.g. when from a timer 
%             we must only migrate a thread when it is stopped, otherwise it's already running and does not need to be woken up
%             but there are states in which the thread is being woken up while going to sleep
%             => cleanly encode running vs stopped in the thread state
%               => more difficult than expected
%               => extend post-switch-to mechanism with appropriate state transitions
%               => TODO see git commit
%               => state diagram with changes made in this step
%             Afterwards, just use the existing thread migration mechanism TODO check if we can go without the IPIs
\blindtext

\section{Stage-Aware Scheduling Policy}\label{ch:di:pol}
% Motivation: bottleneck stages = stages with more-than-avergage threads in the ready queues of processors assigned to these stages
%             natural observation: stage needs more CPU time / cores in our case
%             alterantive formulation (is that correct?):
%                   the time it takes from begin of stage switch to first dispatch on CPU in new stage should be equal among all stages
%                   => predictable latencies
% Design:
%            among all stages, equalize the number of threads that are currently executing / enqueued in each of them
%            why?
%                   => obvious that this eleminiates bottleneck stages
%                   => idea: in systems with #concurrent_requests > #cpus, 
%                   => TODO check queueing theory, would be nice to have some actual formulas here ;)
%
%            equalizing by giving a busy stage more CPUs / taking CPUs from a non-busy stage
%            and between the CPUs assigned to a stage, arbitrate by runqueue length

%              => analogy of requests to be handled = water in pipes...?
%              => a CPU will still have threads from the previous stage in the runqueue: doesn't matter because...
%                    ...they will be migrated off this CPU as soon as they schedule out / block on IO
%                    ...round robin ensures the caches are warm for the remaining threads in the old stage
%                    ... we know the requests will finish processing eventually

% Design Deficiencies:
%              if the runqueues are long, this system reacts slowy
%                   => would need to migrate runqueue threads off-cpu 
%                       => could do this lazily in schedule()
%
% Implementation:
%               track c_in per stage in atomic counters
%               ... see patch, fairly boring
%               max_stages, snapshot runqueue counters 
\blindtext

\chapter{Evaluation}
In this section, we present the evaluation of our design.
We present our hardware setup and describe how we verify the supposed effects of our design decisions using various benchmarks.
This section is very closely related to the previous section.
\section{Evaluation Setup}
\section{Fast Thread Migration}
\section{Work Conservation}
\section{Stage-Aware Scheduling Policy}

\chapter{Conclusion}
\blindtext
\section{Future Work}
\begin{itemize}
    \item at ITEC OS Group: automatic profiling \& finding of migration points.
    \item auto-evaluating scheduler: measure if stage migrations actually make sense by computing a break-even point and continously measuring the result of scheduling decisions using performance conuters.
    \item NUMA / SMT-aware Scheduling Policy
    \item MWAIT
\end{itemize}

\backmatter

\chapter{Appendix}
\blindtext
\begin{itemize}
    \item Source code and commit history of our modified version of OSv
    \item Source code and commit history of our modified version of MySQL 5.6
    \item Source code and commit history of our microbenchmarks and measurement scripts
\end{itemize}

\cleardoublepage
\phantomsection
\addcontentsline{toc}{chapter}{Bibliography}
\printbibliography

\end{document}
